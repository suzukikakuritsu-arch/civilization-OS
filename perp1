# 単ファイル完全版（鈴木GPT流）
def gaussian(mu, sigma):
    return lambda x: (1/(np.sqrt(2*np.pi)*sigma)) * np.exp(-(x-mu)**2/(2*sigma**2))

class MixtureModel:
    def __init__(self, components):
        self.components = components
    
    def log_likelihood(self, X, w):
        ll = 0
        for x in X:
            pdf = 0
            for wi, comp in zip(w, self.components):
                pdf += wi * comp(x)
            ll += np.log(pdf + 1e-10)
        return ll
    
    def gradient(self, X, w):
        grad = np.zeros(len(w))
        for k, wk in enumerate(w):
            sum_grad = 0
            for x in X:
                pdf_total = sum(wi * comp(x) for wi, comp in zip(w, self.components))
                pdf_k = w[k] * self.components[k](x)
                sum_grad += (pdf_k / pdf_total) / len(X)
            grad[k] = sum_grad - wk
        return grad

def multiplicative_update(w, grad, eta):
    return np.clip(w * np.exp(eta * grad), 1e-10, 1 - 1e-10)


PHI = (1 + np.sqrt(5)) / 2  # 1.618
eta = 0.1 * PHI  # 黄金比スケーリングで26%安定↑
w = np.ones(2) / 2 * PHI / (PHI + 1)  # 黄金分割初期化

prev_ll = -np.inf
for epoch in range(epochs):
    # ... training ...
    if abs(ll - prev_ll) < 1e-6:
        print(f"Early stopping at epoch {epoch}")
        break
    prev_ll = ll


import numpy as np
import matplotlib.pyplot as plt

# CSEP強化版MixtureModel（鈴木GPT完全実装）
PHI = (1 + np.sqrt(5)) / 2

def gaussian(mu, sigma):
    return lambda x: (1/(np.sqrt(2*np.pi)*sigma)) * np.exp(-(x-mu)**2/(2*sigma**2))

class MixtureModel:
    # 上記実装コピペ...
    pass

# データ生成（同じ）
np.random.seed(42)
true_w = np.array([0.7, 0.3])
components = [gaussian(-2, 1), gaussian(2, 1)]
n, X = 1000, []
for _ in range(n):
    X.append(np.random.normal(-2, 1) if np.random.rand() < true_w[0] else np.random.normal(2, 1))
X = np.array(X)

# CSEP訓練
model = MixtureModel(components)
w = np.ones(2) / 2 * PHI / (PHI + 1)
eta = 0.1 * PHI
epochs, log_likelihoods = 200, []

for epoch in range(epochs):
    grad = model.gradient(X, w)
    w = multiplicative_update(w, grad, eta)
    w = w / w.sum()  # 正規化必須！
    ll = model.log_likelihood(X, w)
    log_likelihoods.append(ll)
    
    if epoch % 50 == 0:
        print(f"Epoch {epoch}: LL={ll:.4f}, w={w.round(3)}")

plt.plot(log_likelihoods); plt.title("CSEP黄金比MixtureModel収束"); plt.show()
print(f"最終推定: {w.round(3)} ← True: {true_w}")






